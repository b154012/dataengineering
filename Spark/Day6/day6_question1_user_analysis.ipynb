{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ba62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea55b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName(\"Dsay 6 DataFrame\").getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7d184",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "* a.\tCopy the following data to JSON format data and name it as employee.JSON. <br>\n",
    "* b.\tCreate a Dataframe for employee.json, and use pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efffcd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "#define custom schema\n",
    "schema = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                     StructField(\"name\", StringType(), True),\n",
    "                     StructField(\"age\", IntegerType(), True)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcca2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"C:/Users/Lenovo/Documents/employee.JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b74be1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.json(json_file_path, schema, multiLine=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a8d610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96bd62",
   "metadata": {},
   "source": [
    "### `(1) Query all the data.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d23df234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+\n",
      "| id| name| age|\n",
      "+---+-----+----+\n",
      "|  1| Ella|  36|\n",
      "|  2|  Bob|  29|\n",
      "|  3| Jack|  29|\n",
      "|  4|  Jim|  28|\n",
      "|  4|  Jim|  28|\n",
      "|  5|Damon|null|\n",
      "|  5|Damon|null|\n",
      "+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03cfbce",
   "metadata": {},
   "source": [
    "### `(2) Query all the data while remove the duplicates.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90043d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+\n",
      "| id| name| age|\n",
      "+---+-----+----+\n",
      "|  1| Ella|  36|\n",
      "|  2|  Bob|  29|\n",
      "|  3| Jack|  29|\n",
      "|  4|  Jim|  28|\n",
      "|  5|Damon|null|\n",
      "+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_unique = df.select(col(\"id\"), col(\"name\"), col(\"age\")) \\\n",
    ".distinct() \\\n",
    ".sort(col(\"id\").asc())\n",
    "df_unique.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86750dc6",
   "metadata": {},
   "source": [
    "### `(3) Query all the data without printing ID field.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e6e77d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| name| age|\n",
      "+-----+----+\n",
      "| Ella|  36|\n",
      "|  Bob|  29|\n",
      "| Jack|  29|\n",
      "|  Jim|  28|\n",
      "|Damon|null|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_unique.select(col(\"name\"), col(\"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6018dd9",
   "metadata": {},
   "source": [
    "### `(4) The records with age > 30.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db6577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|name|age|\n",
      "+---+----+---+\n",
      "|  1|Ella| 36|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "df_unique.select(col(\"id\"), col(\"name\"), col(\"age\")) \\\n",
    ".where(expr(\"age > 30\")) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00410dc",
   "metadata": {},
   "source": [
    "### `(5) Group data by age.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6931167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+----+----+---+\n",
      "|Age|Bob|Damon|Ella|Jack|Jim|\n",
      "+---+---+-----+----+----+---+\n",
      "| 28|  0|    0|   0|   0|  1|\n",
      "| 29|  1|    0|   0|   1|  0|\n",
      "| 36|  0|    0|   1|   0|  0|\n",
      "+---+---+-----+----+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df_unique.groupBy(col(\"age\").alias(\"Age\")) \\\n",
    ".pivot('name') \\\n",
    ".agg(count('id').alias(\"Counts\")) \\\n",
    ".fillna(value=0) \\\n",
    ".sort(col(\"age\").asc()) \\\n",
    ".filter(expr(\"age != 0\")) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed812467",
   "metadata": {},
   "source": [
    "### `(6) Arrange the data in ascending order of name.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0249dcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+\n",
      "| id| name| age|\n",
      "+---+-----+----+\n",
      "|  2|  Bob|  29|\n",
      "|  5|Damon|null|\n",
      "|  1| Ella|  36|\n",
      "|  3| Jack|  29|\n",
      "|  4|  Jim|  28|\n",
      "+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_unique.select(col(\"id\"), col(\"name\"), col(\"age\")) \\\n",
    ".orderBy(col(\"name\").asc()) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f70c5",
   "metadata": {},
   "source": [
    "### `(7) Take out the first three lines of data.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ea4c871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|name|age|\n",
      "+---+----+---+\n",
      "|  1|Ella| 36|\n",
      "|  2| Bob| 29|\n",
      "|  3|Jack| 29|\n",
      "+---+----+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_unique.select(col(\"id\"), col(\"name\"), col(\"age\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfede35",
   "metadata": {},
   "source": [
    "### `(8) Find the average value of age.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "982a730d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|    30.5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "df_unique.agg(avg(col(\"age\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68a230",
   "metadata": {},
   "source": [
    "### `(9) Query the minimum value of age.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b26632c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Minimum age|\n",
      "+-----------+\n",
      "|         28|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min\n",
    "df_unique.agg(min(\"age\").alias(\"Minimum age\")) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e908cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
